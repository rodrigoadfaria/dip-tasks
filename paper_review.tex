\begin{enumerate}
  \item \textbf{Resumo}
    \begin{enumerate}[label*=\arabic*.]
      \item \textbf{Motivação}

O artigo contextualiza o cenário atual no que diz respeito à manipulação de imagens por ferramentas de edição, ressaltando a ampla gama de técnicas que essas ferramentas possuem e que permitem aos seus usuários a manipulação de imagens com extrema facilidade, o que implica em uma análise detalhista por um profissional especializado para descobrir qualquer tipo de fraude.
\\[6pt]
Aliado a este fator, pode-se destacar ainda que pessoas podem coletar evidências de crimes ou eventos quaisquer de uma forma trivial, considerando a difusão de dispositivos móveis equipados com câmeras de boa qualidade em qualquer lugar do mundo.
\\[6pt]
Podemos afirmar que ainda não há crise na área pesquisada, porém, tendências de mercado norteiam para que processos historicamente feitos sob arquivos impressos e com a presença dos envolvidos, sejam totalmente realizados por plataformas online, o que pode, futuramente, causar grandes transtornos às empresas e ao estado de um modo geral pelo risco de desvio de conduta e possibilidades de fraudes em processos sigilosos, de grande valor agregado, avaliações contratuais, etc.
\\[6pt]
Não é demasiado lembrar que processos judiciais já são interpretados com ajuda de imagens digitais, o que nos remete a necessidade de garantir a autenticidade das mesmas, assim como também no jornalismo, cuja integridade pode ser colocada em xeque em casos de adulteração de fotos em quaisquer publicações.
\\[6pt]
Sendo assim, a motivação principal do trabalho proposto é de criar uma ferramenta capaz de avaliar uma dada imagem, de forma que qualquer pessoa comum, entenda-se por aquela que não tem conhecimento específico na área de processamento de imagens, possa identificar potenciais alterações, sem a necessidade de auxílio de um analista forense, por exemplo.
\\[6pt]
Tal ferramenta deve ser uma plataforma web, disponível em larga escala, sendo que uma das principais técnicas abordadas pelos autores para compor a paleta de funcionalidades do serviço é o Error Level Analysis (ELA).
\\[6pt]
É sabido que imagens JPEG perdem informação durante a compactação e uma certa quantidade de erro é introduzida cada vez que uma imagem JPEG é comprimida / salva novamente \cite{krawetz}. Logo, cada pixel contém um certo nível de erro, e a execução de uma nova compressão irá alterar o nível de erro do mesmo. No entanto, se uma imagem é manipulada, é muito provável que as diferentes partes da imagem terão diferentes níveis de erro, e o ELA é uma técnica que se concentra neste artefato para identificar se uma imagem foi manipulada e encontrar regiões adulteradas \cite{krawetz}.
\\[6pt]
\item \textbf{Contribuição}

Do ponto de vista de mercado, o trabalho apresentado visa um nicho não explorado pelos concorrentes avaliados, já que fornece um serviço com resultados de detecção mais informativo do que outras plataformas disponíveis.
\\[6pt]
Em outras palavras, os concorrentes focam apenas em análises de baixo nível das imagens e o serviço proposto, além das funcionalidades encontradas nos concorrentes avaliados, também adiciona suporte a outras avaliações de alto nível, tais como, detecção de regiões na imagem que foram copiadas/coladas.
\\[6pt]
Por outro lado, do ponto de vista técnico e científico, o autor ressalta que o ELA tem uma desvantagem: a região de alta frequência na imagem dada afetará o resultado, já que a compressão JPEG na imagem, naturalmente, comprime mais as regiões de alta frequência e, sendo assim, a parte de alta frequência de uma imagem terá, geralmente, uma maior queda nos níveis de erro, mesmo que não seja adulterada.
\\[6pt]
O autor propõe, então, superar esta deficiência do método criando uma máscara de baixa frequência que é gerada pela execução de um filtro gaussiano na imagem e medindo a diferença entre a imagem dada e a imagem filtrada, já que as regiões de baixa frequência terão alterações menores após filtro o gaussiano. 
\\[6pt]
Em seguida, esta máscara é multiplicada em cada um dos três canais diferentes da imagem resultante do ELA, o que auxilia na percepção visual das diferenças. Além disso, regiões de baixa frequência serão destacadas para demonstrar regiões com alto risco de terem sofrido alterações.
\\[6pt]
Outras técnicas também foram apresentadas, com o intuito de integração na plataforma web que está sob desenvolvimento pela equipe em questão. Considerando o processo de codificação de uma imagem, deu-se foco na etapa de quantização, já que nesta etapa, o processo de codificação pode deixar rastros que permitem descobrir se uma imagem foi manipulada ou não. Uma delas é o \textit{blocking artifact measurement} e a outra é o próprio ELA, com um realce no aspecto visual, no intuito de melhorar a experiência proporcionada pelo método original.
\\[6pt]
Uma outra técnica citada foi a análise de metadados, que consiste em avaliar algumas informações tais como, a ferramenta que foi utilizada para criar a imagem e, no caso de uma possível alteração, a ferramenta que alterou a imagem, que ficam gravadas no arquivo. Quando da alteração por um \textit{smartphone}, o sistema operacional também fica armazenado. Outra informação importante é data de criação e/ou alteração da imagem. Apesar de serem características que podem ser um indicativo de que a imagem foi alterada, nada garante que terceiros tentem burlar, também, o conteúdo relativo ao metadado da imagem.
\\[6pt]
\item \textbf{Metodologia}

O método então utilizado pelo autor foi calcular a norma L2 dos dados da imagem resultante da aplicação do ELA. Em seguida, um \textit{threshold} é aplicado na mesma imagem. Logo após este passo, o resultado do \textit{threshold} do ELA é submetido a um filtro gaussiano para, então, produzir uma região contínua. Finalmente, a imagem resultante é suavizada e submetida a um novo \textit{threshold} para remover o ruído.
\\[6pt]
Todo este processo cria regiões rotuladas de baixa frequência e regiões com alto índice de ELA tornam-se visualmente mais contundentes, quando da avaliação de qualquer tipo de violação da imagem.
\\[6pt]
De certa forma um novo algoritmo foi implementado, mas não foi apresentado pelos autores, apenas os passos que foram tomados para que pudessem ser gerados os filtros gaussianos, bem como sua aplicação na imagem.
Apesar do método ter sido citado, não há teoremas detalhados no artigo, apenas algumas técnicas, além do ELA, foram citadas, de forma que a ideia principal pudesse ser passada aos leitores. Além disso, o artigo tem um viés bem mais comercial do que técnico-científico, o que o torna muito parecido com um plano de negócio.
\\[6pt]
\item \textbf{Conclusão}

Pode-se destacar que o foco principal do artigo é o ELA, onde a contribuição de um dos autores, Yan Zhao, fica mais evidente, tanto que uma seção foi inteiramente dedicada à sua colaboração no trabalho.
\\[6pt]
Dos experimentos realizados, uma imagem foi dada como exemplo para mostrar a técnica com \textit{blocking artifact measurement}. Com o ELA, 3 \textit{datasets} com imagens manipuladas foram utilizados: \textit{CASIA2 Tampered Image Detection Evaluation Database} que consiste de 7491 imagens autênticas e 5123 adulteradas, o segundo \textit{Columbia Uncompressed Image Splicing Detection Evaluation Dataset} formado por 180 imagens remontadas, fruto de cópia de um recorte da própria imagem ou de uma outra fonte, transposta para outra região e 180 imagens originais e o terceiro é o \textit{Benchmark Dataset} composto, também, por imagens de alta qualidade com regiões adulteradas por cópia e cola.
\\[6pt]
O resultado do método ELA original elaborado por Krawetz \cite{krawetz} foi exibido e, posteriormente, a aplicação do novo método proposto com filtros gaussianos mostram resultados significativos.
\\[6pt]
Além do aspecto visual, Yan Zhao também criou um classificador capaz de decidir se uma imagem foi modificada ou não. A extração dos atributos foi feita com dados numéricos do ELA como a média, a mediana e a variância nos três canais da imagem resultante do ELA. O classificador foi criado com \textit{support vector machine} e \textit{adaptive boosting}, ambos do pacote \textit{Scikitlearn}.
\\[6pt]
Os resultados obtidos com o classificador foram relevantes, sendo uma taxa de acerto de 84.34\% com \textit{support vector machine} e 85.54\% com \textit{adaptive boosting} e árvores de decisão.
\\[6pt]
Apesar dos resultados terem sido expressivos, o experimento com o \textit{dataset} \textit{Benchmark Dataset} não foi bem sucedido, conforme citado pelos autores, mas nenhuma métrica ou medida de erro foi referenciada.
\\[6pt]
Um \textit{benchmark} também foi elaborado com duas empresas diferentes. A primeira, System of Methods and Tools of Digital Processing Technology LLC, conhecida como SMTDP, é uma empresa de tecnologia russa fundada em 2011 que se concentra em automação de processos de negócios e detecções de manipulação de imagens. Algumas das tecnologias usadas pela SMTDP são a análise de metadados de imagem e análise de compressão. A SMTDP concentra-se em parcerias com outras grandes empresas como a Belkasoft e PricewaterhouseCoopers.
\\[6pt]
A segunda empresa é chamada de Verifeyed e está localizada na República Checa. Tanto as ferramentas, quanto o mercado consumidor são diferentes se comparadas com a SMTDP. A Veryfied tem um pacote de software, que é comercializado sob a venda de licenças diretamente aos usuários finais. A tecnologia principal concentra-se em análise de metadados e balística.
\\[6pt]
Ambas têm um posicionamento de mercado diferente do proposto pelos autores.
\\[6pt]
Em suma, o plano de negócios citado tem características de inovação, tanto do ponto de vista mercadológico quanto do tecnológico, já que os autores se preocuparam em melhorar técnicas já existentes com o objetivo de ter um diferencial competitivo.
\\[6pt]
Logo, as práticas já existentes na área podem ser impactadas com as mudanças indicadas, principalmente, pelo fato da plataforma web ser interativa e capaz de dar resultados mais analíticos do que as demais avaliadas como \textit{benchmark}.
\\[6pt]
Os resultados obtidos não são de todo genéricos, já que é possível, ainda assim, alterar uma imagem sem que o método proposto pelo ELA detecte qualquer alteração.
\\[6pt]
Como trabalho futuro, o autor cita que novas ferramentas para auxiliar os usuários a obter uma melhor interpretação do resultado do ELA devem ser criadas e, também, extrair outros dados numéricos que possam ser incluídos como atributos de entrada para os classificadores.
\end{enumerate}



\item \textbf{Crítica}
    \begin{enumerate}[label*=\arabic*.]
      \item \textbf{Capacidade de inovação}
\\[6pt]      
Com exceção do método composto pelo ELA com filtro gaussiano, todos os demais são apenas repetições do estado da arte em análise de imagens.
\\[6pt]
Não há preocupação em relação a comparação dos métodos com outros existentes, já que eles estão sendo utilizados como experimentos para compor as técnicas que estarão disponíveis na plataforma web posteriormente. Isso fica ainda mais evidente na seção \textit{Intellectual Property}, onde os autores chegam à conclusão de que não é possível registrar patente da plataforma web já que ela não atende a dois requisitos das leis dos Estados Unidos para tal, que são:
\\[6pt]
1. A reprodução não pode ser óbvia, o que não ocorre, já que os próprios autores têm receio de serem copiados, uma vez que eles utilizam uma combinação de técnicas que estão disponíveis em outros artigos que estão publicados abertamente.
\\[6pt]
2. Inovação que, pelas mesmas leis, a invenção reivindicada deve ter sido antes de ser patenteada, descrita em uma publicação impressa, ou em uso público, em promoção, ou de outro modo disponível para o público, o que também não ocorre neste caso e, por consequência, dificulta o processo de obtenção de patente.
\\[6pt]
\item \textbf{Ausência de embasamento teórico}

Nenhum algoritmo foi mostrado, poucos conceitos matemáticos, nenhuma prova, o que não garante que o método é totalmente funcional. É difícil até mesmo avaliar qualquer tipo de erro conceitual, uma vez que maiores detalhes não foram fornecidos, acredito que de forma propositada, para evitar que detalhes do método fossem publicados inadvertidamente, oferecendo risco ao negócio como um todo.
\\[6pt]
Outro ponto já observado, o experimento com o \textit{dataset} \textit{Benchmark Dataset} não foi bem sucedido, conforme citado pelos autores, mas nenhuma métrica ou medida de erro foi detalhada.
\end{enumerate}


\item \textbf{Sugestões}
    \begin{enumerate}[label*=\arabic*.]
\item \textbf{Mudança de paradigma para \textit{open source}}

Uma possível mudança de paradigma seria abrir o código para a comunidade científica para obter sugestões, críticas, elogios e possíveis novas funcionalidades para a plataforma, de forma que não fique limitada a métodos já existentes ou que possam ser facilmente copiados. Com isso, as técnicas apresentadas podem ser mais bem elaboradas e expostas, sem qualquer tipo de problema em relação a segredo industrial ou patente envolvida.
\\[6pt]
Com este mesmo viés, a contribuição de outros grupos de pesquisa podem incluir embasamento teórico e fundamentado para este e novos métodos propostos.
    \end{enumerate}
\end{enumerate}
